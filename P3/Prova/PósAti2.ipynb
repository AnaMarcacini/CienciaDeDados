{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rownames</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  V1  V2  V3  V4  V5    V6  V7  V8  V9   class\n",
       "rownames                                                       \n",
       "1         1000025   5   1   1   1   2   1.0   3   1   1  benign\n",
       "2         1002945   5   4   4   5   7  10.0   3   2   1  benign\n",
       "3         1015425   3   1   1   1   2   2.0   3   1   1  benign\n",
       "4         1016277   6   8   8   1   3   4.0   3   7   1  benign\n",
       "5         1017023   4   1   1   3   2   1.0   3   1   1  benign"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       0.00000\n",
       "V1       0.00000\n",
       "V2       0.00000\n",
       "V3       0.00000\n",
       "V4       0.00000\n",
       "V5       0.00000\n",
       "V6       0.02289\n",
       "V7       0.00000\n",
       "V8       0.00000\n",
       "V9       0.00000\n",
       "class    0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       0.0\n",
       "V1       0.0\n",
       "V2       0.0\n",
       "V3       0.0\n",
       "V4       0.0\n",
       "V5       0.0\n",
       "V6       0.0\n",
       "V7       0.0\n",
       "V8       0.0\n",
       "V9       0.0\n",
       "class    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "df.isnull().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previs√£o para o percentil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benign' 'benign' 'malignant' 'benign' 'benign' 'malignant' 'benign'\n",
      " 'benign' 'benign' 'benign'] ...\n",
      "0.9380952380952381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors = 9)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print( y_pred[0:10], '...' )\n",
    "print( clf.score(X_test,y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1   V2   V3   V4   V5    V6   V7   V8   V9\n",
       "0  1.0  1.0  1.0  1.0  2.0   1.0  1.0  1.0  1.0\n",
       "1  2.0  1.0  1.0  1.0  2.0   1.0  2.0  1.0  1.0\n",
       "2  6.0  5.0  5.0  4.0  4.0   5.0  5.0  4.0  1.0\n",
       "3  9.0  9.0  8.0  8.0  6.0  10.0  7.0  9.0  3.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se considerarmos 0.93 um bom resultado podemos ent√£o aplicar o modelo para novos casos. Por exemplo, podemos fazer predi√ß√£o considerando pacientes hipot√©ticos valores das medidas v1-v9 dos tumores nos percentis  [0.10,0.25,0.75,0.90] \n",
    "\n",
    "X_new = pd.DataFrame( df.drop(columns=['ID','class']).quantile([0.10, 0.25, 0.75, 0.90]) ).reset_index(drop=True)\n",
    "display(X_new)\n",
    "X_new_scaled = scaler.transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['benign', 'benign', 'malignant', 'malignant'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escolha de Hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num exemplo anterior empregamos o modelo Knn com k=9, uma escolha arbitr√°ria, e a fun√ß√£o de dist√¢ncia euclidiana. Ser√° que haveria hiperpar√¢metros que apresentassem um desempenho melhor?\n",
    "\n",
    "A escolha de melhores hiperpar√¢metros √© em geral por experimenta√ß√£o uma vez que n√£o existem hiperpar√¢metros melhores apriori para quaisquer conjuntos de dados. A ideia, ent√£o, √© criarmos os diferentes modelos e avaliarmos o desempenho de cada um para obtermos os melhores hiperpar√¢metros.\n",
    "\n",
    "Podemos ent√£o adaptar o nosso c√≥digo do modelo Knn anterior para, por exemplo, variar os hiperpar√¢metros k, no range de valores de 2 a 10 e experimentar o resultado das fun√ß√µes dist√¢ncia 'euclidean' e 'manhattan'. manhattan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### teoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 euclidean 0.9095\n",
      "2 manhattan 0.9286\n",
      "3 euclidean 0.9429\n",
      "3 manhattan 0.9381\n",
      "4 euclidean 0.9381\n",
      "4 manhattan 0.9333\n",
      "5 euclidean 0.9429\n",
      "5 manhattan 0.9333\n",
      "6 euclidean 0.9381\n",
      "6 manhattan 0.9286\n",
      "7 euclidean 0.9429\n",
      "7 manhattan 0.9333\n",
      "8 euclidean 0.9381\n",
      "8 manhattan 0.9333\n",
      "9 euclidean 0.9381\n",
      "9 manhattan 0.9381\n",
      "10 euclidean 0.9381\n",
      "10 manhattan 0.9429\n"
     ]
    }
   ],
   "source": [
    "## NO BRA√áO\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "for k, d in [(k,d) for k in range(2,11) for d in ['euclidean','manhattan']]:\n",
    "\n",
    "  clf = neighbors.KNeighborsClassifier(n_neighbors = k, metric= d )\n",
    "\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = clf.predict(X_test)\n",
    "\n",
    "  print( k, d, np.round( clf.score(X_test,y_test), 4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora tendo escolhido os conjuntos de treinamento e teste de forma aleat√≥ria o resultado acima, pode depender do par (treinamento, teste) escolhido.\n",
    "\n",
    "> *Tire o par√¢metro `random_state=123` do c√≥digo acima e veja que a cada nova execu√ß√£o diferentes valores de acuracidade s√£o produzidos para os mesmos par√¢metros. Assim, para obtermos uma medida mais efetiva dos modelos, precisamos executar sobre um grande n√∫mero de diferentes conjuntos de teste.*\n",
    "\n",
    "Para n√£o considerarmos o resultado de uma √∫nica amostra, podemos fazer v√°rias execu√ß√µes a obter a m√©dia dos valores sobre v√°rias amostras, o que ser√° uma medida independente de um par espec√≠fico de dados e uma melhor aproxima√ß√£o do resultado esperado do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.909524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k     metric     score\n",
       "0   2  euclidean  0.909524\n",
       "1   2  manhattan  0.928571\n",
       "2   3  euclidean  0.942857\n",
       "3   3  manhattan  0.938095\n",
       "4   4  euclidean  0.938095\n",
       "5   4  manhattan  0.933333\n",
       "6   5  euclidean  0.942857\n",
       "7   5  manhattan  0.933333\n",
       "8   6  euclidean  0.938095\n",
       "9   6  manhattan  0.928571\n",
       "10  7  euclidean  0.942857\n",
       "11  7  manhattan  0.933333\n",
       "12  8  euclidean  0.938095\n",
       "13  8  manhattan  0.933333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best result:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k     metric     score\n",
       "2  3  euclidean  0.942857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_means = {}\n",
    "\n",
    "for k, d in [(k,d) for k in range(2,9) for d in ['euclidean','manhattan']]:\n",
    "\n",
    "  scores = []\n",
    "  for i in range(0,25):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors = k, metric= d )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    scores.append(clf.score(X_test,y_test))\n",
    "\n",
    "  scores_means[(k,d)] = np.mean(scores)\n",
    "\n",
    "scores_means = pd.DataFrame(scores_means.values(), index=scores_means.keys()).reset_index()\n",
    "scores_means.columns = ['k','metric','score']\n",
    "\n",
    "display(scores_means)\n",
    "print('\\nBest result:\\n')\n",
    "display(scores_means.nlargest(1,'score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desse modo, conclu√≠mos que para o nosso conjunto de dados os melhores resultados com o modelo knn s√£o obtidos com os par√¢metros k=3 e a m√©trica Euclidiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>criterion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.940190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.921714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.919048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.925905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.920952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth criterion     score\n",
       "0          2      gini  0.933333\n",
       "1          2   entropy  0.923810\n",
       "2          3      gini  0.940190\n",
       "3          3   entropy  0.923810\n",
       "4          4      gini  0.921714\n",
       "5          4   entropy  0.919048\n",
       "6          5      gini  0.925905\n",
       "7          5   entropy  0.920952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best result:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>criterion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.94019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth criterion    score\n",
       "2          3      gini  0.94019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# para arvore de decis√£o\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "scores_means = {}\n",
    "\n",
    "for max_depth, criterion in [(max_depth, criterion) for max_depth in range(2,6) for criterion in ['gini','entropy']]:\n",
    "\n",
    "  scores = []\n",
    "  for i in range(0,25):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    scores.append(clf.score(X_test,y_test))\n",
    "\n",
    "  scores_means[(max_depth, criterion)] = np.mean(scores)\n",
    "\n",
    "scores_means = pd.DataFrame(scores_means.values(), index=scores_means.keys()).reset_index()\n",
    "scores_means.columns = ['max_depth', 'criterion' ,'score']\n",
    "\n",
    "display(scores_means)\n",
    "print('\\nBest result:\\n')\n",
    "display(scores_means.nlargest(1,'score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Aqui o melhor modelo de √Årvore de Decis√£o apresenta um score inferior ao do modelo de K-Vizinhos mais Pr√≥ximos como k=3 e m√©trica euclidiana e, assim, optar√≠amos por este √∫ltimo se levarmos somente o crit√©rio de acuracidade como o crit√©rio de sele√ß√£o do melhor modelo, e uma alternativa comum √© empregarmos o F1, e o procedimento poderia ser o mesmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pratica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O √∫ltimo refinamento que faremos no procedimento de busca de melhores hiperpar√¢metros consiste em empregarmos GridSearchCV() do scikit-learn. Essa fun√ß√£o automatiza a busca de melhores hiperpar√¢metros que fizemos acima implementando de forma manual os diferentes estimadores para um espa√ßo de hiperpar√¢metros em for k, d in [(k,d) for k in range(2,9) for d in ['euclidean','manhattan']]:... e podendo ser aplicada a qualquer estimador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Qualquer par√¢metro de um estimador pode ser otimizado desta maneira e para encontrar os nomes e valores dos par√¢metros de um determinado estimador voc√™ pode empregar o m√©todo estimator.get_params()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of KNeighborsClassifier()>\n",
      "<bound method BaseEstimator.get_params of LogisticRegression()>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DecisionTreeClassifier(criterion='entropy', max_depth=3)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier()\n",
    "print(clf.get_params)\n",
    "# e do mesmo modo os hiperpar√¢metros da regress√£o log√≠stica s√£o tamb√©m obtidos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "print(LogisticRegression().get_params)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, criterion='entropy')\n",
    "clf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(metric='manhattan')\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.94      0.96      0.95       138\n",
      "   malignant       0.91      0.89      0.90        72\n",
      "\n",
      "    accuracy                           0.93       210\n",
      "   macro avg       0.93      0.92      0.93       210\n",
      "weighted avg       0.93      0.93      0.93       210\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "base_estimator = neighbors.KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': [3,4,5,6,7,8,9,10], 'metric': ['euclidean','manhattan']}\n",
    "\n",
    "clf = GridSearchCV(base_estimator, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Por padr√£o as fun√ß√µes de pesquisa em grade, como o GridSearchCV() empregam o score padr√£o do estimador como fun√ß√£o de pontua√ß√£o (no caso de classifica√ß√£o √© o accuracy), mas deixamos expl√≠cito o par√¢metro pois voc√™ poderia querer empregar uma fun√ß√£o de pontua√ß√£o dos estimadores baseada em outra m√©trica.\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# print(clf.cv_results_)\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00652928, 0.00570097, 0.00681386, 0.00757079, 0.00458994,\n",
      "       0.00600152, 0.0065135 , 0.00782247, 0.00463891, 0.00564442,\n",
      "       0.02208323, 0.00770912, 0.00472965, 0.00576663, 0.00668273,\n",
      "       0.00782661, 0.00458245, 0.00566788, 0.00647326, 0.00737758,\n",
      "       0.00458941, 0.00573297, 0.00656924, 0.00761051, 0.00465937,\n",
      "       0.00581107, 0.00669041, 0.00768285, 0.00470223, 0.00570092,\n",
      "       0.00676513, 0.00773587]), 'std_fit_time': array([1.26768844e-03, 3.75386569e-04, 3.86738529e-04, 2.35699667e-04,\n",
      "       6.00937044e-05, 6.92466418e-04, 3.84156185e-05, 4.38801902e-04,\n",
      "       3.19320724e-05, 9.10415135e-05, 3.05477411e-02, 9.54454341e-05,\n",
      "       6.68133091e-05, 1.10020810e-04, 1.67766736e-05, 1.20808499e-04,\n",
      "       7.20963591e-05, 2.00688088e-04, 8.05780588e-05, 6.71696524e-05,\n",
      "       8.51632499e-05, 9.61218321e-05, 4.03158979e-05, 1.21878626e-04,\n",
      "       6.30807803e-05, 1.99629549e-04, 5.82230862e-05, 3.05262941e-05,\n",
      "       1.14618065e-04, 3.59803891e-05, 1.45170487e-04, 7.75681721e-05]), 'mean_score_time': array([0.00161972, 0.00114713, 0.00122261, 0.00120544, 0.00110569,\n",
      "       0.00131521, 0.00116863, 0.00122738, 0.00112309, 0.00116692,\n",
      "       0.00128589, 0.00122471, 0.00111613, 0.001194  , 0.00119348,\n",
      "       0.00123405, 0.00112944, 0.00119848, 0.00118999, 0.00120039,\n",
      "       0.00111222, 0.00124002, 0.00118337, 0.00123901, 0.00112987,\n",
      "       0.00119777, 0.00121694, 0.00122294, 0.00112476, 0.00116   ,\n",
      "       0.00119324, 0.00123672]), 'std_score_time': array([2.77973554e-04, 1.74808788e-05, 4.61151087e-05, 2.78143655e-05,\n",
      "       2.13719882e-05, 2.72275587e-04, 2.07150487e-05, 3.11823794e-05,\n",
      "       1.90302836e-05, 1.94229068e-05, 5.43156247e-05, 1.90301642e-05,\n",
      "       8.81259057e-06, 5.17259534e-05, 2.22848814e-05, 3.45961707e-05,\n",
      "       3.64988866e-05, 8.21278331e-05, 3.39732337e-05, 1.40447769e-05,\n",
      "       1.63611439e-05, 3.87756870e-05, 1.64992547e-05, 5.86008230e-05,\n",
      "       3.05492267e-05, 5.95404088e-05, 4.32928752e-05, 2.60366188e-05,\n",
      "       2.65022815e-05, 1.59655734e-05, 1.53948263e-05, 2.95844314e-05]), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=np.str_('?'),\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 2, 2,\n",
      "                   2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=999999), 'param_n_estimators': masked_array(data=[3, 4, 5, 6, 3, 4, 5, 6, 3, 4, 5, 6, 3, 4, 5, 6, 3, 4,\n",
      "                   5, 6, 3, 4, 5, 6, 3, 4, 5, 6, 3, 4, 5, 6],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=999999), 'params': [{'criterion': 'gini', 'max_depth': 2, 'n_estimators': 3}, {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 4}, {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 5}, {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 6}, {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 3}, {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 4}, {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 5}, {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 6}, {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 3}, {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 4}, {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 5}, {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 6}, {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 3}, {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 4}, {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 5}, {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 6}, {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 3}, {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 4}, {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 5}, {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 6}, {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 3}, {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 4}, {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 5}, {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 6}, {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 3}, {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 4}, {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 5}, {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 6}, {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 3}, {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 4}, {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 5}, {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 6}], 'split0_test_score': array([0.94897959, 0.92857143, 0.94897959, 0.92857143, 0.89795918,\n",
      "       0.91836735, 0.91836735, 0.91836735, 0.89795918, 0.94897959,\n",
      "       0.92857143, 0.93877551, 0.93877551, 0.95918367, 0.93877551,\n",
      "       0.94897959, 0.98979592, 0.98979592, 0.97959184, 0.96938776,\n",
      "       0.97959184, 0.95918367, 0.97959184, 0.95918367, 0.92857143,\n",
      "       0.94897959, 0.96938776, 0.95918367, 0.95918367, 0.95918367,\n",
      "       0.97959184, 0.95918367]), 'split1_test_score': array([0.96938776, 0.96938776, 0.93877551, 0.94897959, 0.94897959,\n",
      "       0.95918367, 0.96938776, 0.95918367, 0.97959184, 0.97959184,\n",
      "       0.96938776, 0.96938776, 0.96938776, 0.97959184, 0.96938776,\n",
      "       0.95918367, 0.94897959, 0.94897959, 0.92857143, 0.92857143,\n",
      "       0.93877551, 0.94897959, 0.95918367, 0.94897959, 0.96938776,\n",
      "       0.97959184, 0.97959184, 0.96938776, 0.97959184, 0.97959184,\n",
      "       0.96938776, 0.96938776]), 'split2_test_score': array([0.94897959, 0.93877551, 0.94897959, 0.94897959, 0.93877551,\n",
      "       0.94897959, 0.95918367, 0.95918367, 0.96938776, 0.94897959,\n",
      "       0.95918367, 0.95918367, 0.97959184, 0.93877551, 0.95918367,\n",
      "       0.95918367, 0.94897959, 0.95918367, 0.95918367, 0.95918367,\n",
      "       0.94897959, 0.94897959, 0.96938776, 0.96938776, 0.95918367,\n",
      "       0.95918367, 0.95918367, 0.95918367, 0.96938776, 0.95918367,\n",
      "       0.96938776, 0.96938776]), 'split3_test_score': array([0.94897959, 0.94897959, 0.92857143, 0.93877551, 0.94897959,\n",
      "       0.94897959, 0.94897959, 0.96938776, 0.94897959, 0.94897959,\n",
      "       0.95918367, 0.95918367, 0.93877551, 0.93877551, 0.94897959,\n",
      "       0.93877551, 0.95918367, 0.91836735, 0.91836735, 0.94897959,\n",
      "       0.94897959, 0.94897959, 0.95918367, 0.95918367, 0.95918367,\n",
      "       0.95918367, 0.95918367, 0.95918367, 0.95918367, 0.95918367,\n",
      "       0.95918367, 0.95918367]), 'split4_test_score': array([0.98969072, 0.98969072, 0.98969072, 0.98969072, 0.97938144,\n",
      "       0.97938144, 0.96907216, 0.95876289, 0.96907216, 0.96907216,\n",
      "       0.98969072, 0.98969072, 0.96907216, 0.96907216, 0.97938144,\n",
      "       0.97938144, 0.98969072, 0.98969072, 0.98969072, 0.98969072,\n",
      "       0.97938144, 0.98969072, 0.98969072, 0.98969072, 0.98969072,\n",
      "       0.97938144, 0.98969072, 0.97938144, 0.98969072, 0.98969072,\n",
      "       1.        , 0.98969072]), 'mean_test_score': array([0.96120345, 0.955081  , 0.95099937, 0.95099937, 0.94281506,\n",
      "       0.95097833, 0.95299811, 0.95297707, 0.95299811, 0.95912056,\n",
      "       0.96120345, 0.96324427, 0.95912056, 0.95707974, 0.95914159,\n",
      "       0.95710078, 0.9673259 , 0.96120345, 0.955081  , 0.95916263,\n",
      "       0.95914159, 0.95916263, 0.97140753, 0.96528508, 0.96120345,\n",
      "       0.96526404, 0.97140753, 0.96526404, 0.97140753, 0.96936672,\n",
      "       0.9755102 , 0.96936672]), 'std_test_score': array([0.01628972, 0.02194707, 0.02077313, 0.02077313, 0.02623536,\n",
      "       0.01972577, 0.01887165, 0.01776324, 0.02925629, 0.01285788,\n",
      "       0.01975609, 0.01654602, 0.0170374 , 0.01627961, 0.01437137,\n",
      "       0.01346755, 0.01867917, 0.02689791, 0.02780682, 0.02037662,\n",
      "       0.01702453, 0.01576736, 0.01186746, 0.01380428, 0.01975609,\n",
      "       0.012196  , 0.01186746, 0.00808973, 0.01186746, 0.01287402,\n",
      "       0.01384149, 0.01113961]), 'rank_test_score': array([12, 24, 29, 29, 32, 31, 26, 28, 27, 20, 12, 11, 21, 23, 18, 22,  7,\n",
      "       12, 25, 16, 18, 16,  2,  8, 12,  9,  2,  9,  2,  5,  1,  6],\n",
      "      dtype=int32)}\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=5,\n",
      "                       random_state=123)\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.98      0.94      0.96       138\n",
      "   malignant       0.90      0.97      0.93        72\n",
      "\n",
      "    accuracy                           0.95       210\n",
      "   macro avg       0.94      0.96      0.95       210\n",
      "weighted avg       0.95      0.95      0.95       210\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anahelena/.local/lib/python3.12/site-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "base_estimator = RandomForestClassifier(random_state=123)\n",
    "param_grid = {'n_estimators':[3,4,5,6],'criterion':['gini','entropy'],'max_depth':[2,3,4,5]}\n",
    "\n",
    "clf = GridSearchCV(base_estimator, param_grid, cv=5, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.cv_results_)\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Selecionar um estimador (um classificador ou um regressor)\n",
    "* Definir um espa√ßo de hiperpar√¢metros que desejamos avaliar\n",
    "* Definir uma fun√ß√£o de pontua√ß√£o (score function)\n",
    "* Empregar um esquema de valida√ß√£o cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc_scores = cross_val_score(clf, X_train, y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![imagem](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97959184 0.93877551 1.         0.97959184 0.95918367 0.95918367\n",
      " 1.         0.93877551 0.97959184 0.95833333] \n",
      "\n",
      "accuracy: 0.969 +/- 0.042 \n",
      "\n",
      "accuracy: 0.971 +/- 0.008\n",
      "f1_macro: 0.968 +/- 0.009\n",
      "precision_macro: 0.970 +/- 0.009\n",
      "recall_macro: 0.967 +/- 0.018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 3, metric= 'euclidean' )\n",
    "\n",
    "acc_scores = cross_val_score(clf, X_train, y_train, cv = 10)\n",
    "\n",
    "print(acc_scores, '\\n')\n",
    "print(\"accuracy: %0.3f +/- %0.3f\" % (acc_scores.mean(), acc_scores.std() * 2),'\\n')\n",
    "\n",
    "for metric in ['accuracy','f1_macro','precision_macro','recall_macro']:\n",
    "  scores = cross_val_score(clf, X_train, y_train, cv = 4, scoring=metric)\n",
    "  print(metric + \": %0.3f +/- %0.3f\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "4       3450.0  Female  \n",
       "5       3650.0    Male  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = sns.load_dataset('penguins')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treinamento e teste\n",
    "# As features (X) e o alvo (y)\n",
    "X = df[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
    "y = df['species']\n",
    "\n",
    "# Dividindo em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "# Criando o dicion√°rio de modelos que iremos testar\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O obtenha a acuracidade m√©dia dos modelos para um cv de 5 parti√ß√µes. Explore a sa√≠da do estimador cross_val_score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest, score = 0.9760\n",
      "DecisionTree, score = 0.9580\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5)\n",
    "    print(f\"{name}, score = {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97014925, 0.98507463, 0.91044776, 0.98484848, 0.93939394])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Acima foram empregadas parti√ß√µes diferentes para cada modelo. Empregue os estimadores KFold (ou alternativamente o StratifiedKFold), para fixar as parti√ß√µes e obtenha o novo score dos modelos fazendo a sele√ß√£o agora pela m√©trica f1_macro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest, score = 0.9756\n",
      "DecisionTree, score = 0.9666\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "    print(f\"{name}, score = {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{RandomForestClassifier(): np.float64(0.9721484905798631),\n",
       " DecisionTreeClassifier(): np.float64(0.960080404872922),\n",
       " LogisticRegression(max_iter=1000): np.float64(0.9823596229934367),\n",
       " KNeighborsClassifier(): np.float64(0.6890947070491956)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empregue o c√≥digo anterior para selecionar programaticamente o melhor modelo, treinar, aplicar ao conjunto de teste e obter a acuracidade nesse conjunto.\n",
    "\n",
    "models_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    models_scores[model] = cross_val_score(model, X, y, cv=kf, scoring='f1_macro').mean()\n",
    "\n",
    "models_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "best_model = max(models_scores, key=models_scores.get)\n",
    "print(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "y_pred = model.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acur√°cia: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'deprecated',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Empregando o `GridSearchCV`. O `GridSearchCV` permite automatizar todas essas opera√ß√µes.\n",
    "\n",
    "Empregue o exemplo de c√≥digo abaixo para corrigir, como fizemos antes, o uso de parti√ß√µes diferentes na avalia√ß√£o dos modelos (use o `KFold`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo: LogisticRegression(max_iter=1000)\n",
      "Acur√°cia no teste: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Criando o pipeline com pr√©-processamento e modelo\n",
    "pipeline = Pipeline([('model', None)])\n",
    "# pipeline = Pipeline([('scaler', StandardScaler()), ('model', None)])\n",
    "\n",
    "# Definindo o dicion√°rio de par√¢metros para o GridSearchCV (somente diferentes modelos)\n",
    "param_grid = [\n",
    "    {'model': [models['RandomForest']]},\n",
    "    {'model': [models['DecisionTree']], 'model__max_depth': [5,6,7]},\n",
    "    {'model': [models['LogisticRegression']]},\n",
    "    {'model': [models['KNN']], 'model__n_neighbors': [3, 5, 7, 9]}\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Usando o GridSearchCV para encontrar o melhor modelo\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=kf, scoring='accuracy')\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=kf, scoring='f1_macro')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibindo o melhor modelo encontrado\n",
    "print(f\"Melhor modelo: {grid_search.best_estimator_['model']}\")\n",
    "\n",
    "# Avaliando o desempenho no conjunto de teste\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acur√°cia no teste: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### + hiperparametros bra√ßal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best result:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.975489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k     metric     score\n",
       "7  5  manhattan  0.975489"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "scores_means = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "for k, d in [(k,d) for k in range(2,9) for d in ['euclidean','manhattan']]:\n",
    "\n",
    "  clf = neighbors.KNeighborsClassifier(n_neighbors = k, metric= d )\n",
    "\n",
    "  acc_scores = cross_val_score(clf, X_train, y_train, cv = 5)\n",
    "\n",
    "  scores_means[(k,d)] = acc_scores.mean()\n",
    "\n",
    "scores_means = pd.DataFrame(scores_means.values(), index=scores_means.keys()).reset_index()\n",
    "scores_means.columns = ['k','metric','score']\n",
    "\n",
    "# display(scores_means)\n",
    "print('\\nBest result:\\n')\n",
    "display(scores_means.nlargest(1,'score'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(metric='manhattan', n_neighbors=np.int64(5))\n",
      "accuracy: 0.933 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicando o melhor modelo\n",
    "\n",
    "k = scores_means.nlargest(1,'score').k.values[0]\n",
    "metric = scores_means.nlargest(1,'score').metric.values[0]\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = k, metric= metric )\n",
    "print(clf)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"accuracy: %0.3f\" % clf.score(X_test,y_test),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
