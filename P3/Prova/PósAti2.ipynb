{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rownames</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  V1  V2  V3  V4  V5    V6  V7  V8  V9   class\n",
       "rownames                                                       \n",
       "1         1000025   5   1   1   1   2   1.0   3   1   1  benign\n",
       "2         1002945   5   4   4   5   7  10.0   3   2   1  benign\n",
       "3         1015425   3   1   1   1   2   2.0   3   1   1  benign\n",
       "4         1016277   6   8   8   1   3   4.0   3   7   1  benign\n",
       "5         1017023   4   1   1   3   2   1.0   3   1   1  benign"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       0.00000\n",
       "V1       0.00000\n",
       "V2       0.00000\n",
       "V3       0.00000\n",
       "V4       0.00000\n",
       "V5       0.00000\n",
       "V6       0.02289\n",
       "V7       0.00000\n",
       "V8       0.00000\n",
       "V9       0.00000\n",
       "class    0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       0.0\n",
       "V1       0.0\n",
       "V2       0.0\n",
       "V3       0.0\n",
       "V4       0.0\n",
       "V5       0.0\n",
       "V6       0.0\n",
       "V7       0.0\n",
       "V8       0.0\n",
       "V9       0.0\n",
       "class    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "df.isnull().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão para o percentil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benign' 'benign' 'malignant' 'benign' 'benign' 'malignant' 'benign'\n",
      " 'benign' 'benign' 'benign'] ...\n",
      "0.9380952380952381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors = 9)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print( y_pred[0:10], '...' )\n",
    "print( clf.score(X_test,y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1   V2   V3   V4   V5    V6   V7   V8   V9\n",
       "0  1.0  1.0  1.0  1.0  2.0   1.0  1.0  1.0  1.0\n",
       "1  2.0  1.0  1.0  1.0  2.0   1.0  2.0  1.0  1.0\n",
       "2  6.0  5.0  5.0  4.0  4.0   5.0  5.0  4.0  1.0\n",
       "3  9.0  9.0  8.0  8.0  6.0  10.0  7.0  9.0  3.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se considerarmos 0.93 um bom resultado podemos então aplicar o modelo para novos casos. Por exemplo, podemos fazer predição considerando pacientes hipotéticos valores das medidas v1-v9 dos tumores nos percentis  [0.10,0.25,0.75,0.90] \n",
    "\n",
    "X_new = pd.DataFrame( df.drop(columns=['ID','class']).quantile([0.10, 0.25, 0.75, 0.90]) ).reset_index(drop=True)\n",
    "display(X_new)\n",
    "X_new_scaled = scaler.transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['benign', 'benign', 'malignant', 'malignant'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escolha de Hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num exemplo anterior empregamos o modelo Knn com k=9, uma escolha arbitrária, e a função de distância euclidiana. Será que haveria hiperparâmetros que apresentassem um desempenho melhor?\n",
    "\n",
    "A escolha de melhores hiperparâmetros é em geral por experimentação uma vez que não existem hiperparâmetros melhores apriori para quaisquer conjuntos de dados. A ideia, então, é criarmos os diferentes modelos e avaliarmos o desempenho de cada um para obtermos os melhores hiperparâmetros.\n",
    "\n",
    "Podemos então adaptar o nosso código do modelo Knn anterior para, por exemplo, variar os hiperparâmetros k, no range de valores de 2 a 10 e experimentar o resultado das funções distância 'euclidean' e 'manhattan'. manhattan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### teoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 euclidean 0.9095\n",
      "2 manhattan 0.9286\n",
      "3 euclidean 0.9429\n",
      "3 manhattan 0.9381\n",
      "4 euclidean 0.9381\n",
      "4 manhattan 0.9333\n",
      "5 euclidean 0.9429\n",
      "5 manhattan 0.9333\n",
      "6 euclidean 0.9381\n",
      "6 manhattan 0.9286\n",
      "7 euclidean 0.9429\n",
      "7 manhattan 0.9333\n",
      "8 euclidean 0.9381\n",
      "8 manhattan 0.9333\n",
      "9 euclidean 0.9381\n",
      "9 manhattan 0.9381\n",
      "10 euclidean 0.9381\n",
      "10 manhattan 0.9429\n"
     ]
    }
   ],
   "source": [
    "## NO BRAÇO\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "for k, d in [(k,d) for k in range(2,11) for d in ['euclidean','manhattan']]:\n",
    "\n",
    "  clf = neighbors.KNeighborsClassifier(n_neighbors = k, metric= d )\n",
    "\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  y_pred = clf.predict(X_test)\n",
    "\n",
    "  print( k, d, np.round( clf.score(X_test,y_test), 4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora tendo escolhido os conjuntos de treinamento e teste de forma aleatória o resultado acima, pode depender do par (treinamento, teste) escolhido.\n",
    "\n",
    "> *Tire o parâmetro `random_state=123` do código acima e veja que a cada nova execução diferentes valores de acuracidade são produzidos para os mesmos parâmetros. Assim, para obtermos uma medida mais efetiva dos modelos, precisamos executar sobre um grande número de diferentes conjuntos de teste.*\n",
    "\n",
    "Para não considerarmos o resultado de uma única amostra, podemos fazer várias execuções a obter a média dos valores sobre várias amostras, o que será uma medida independente de um par específico de dados e uma melhor aproximação do resultado esperado do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.909524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k     metric     score\n",
       "0   2  euclidean  0.909524\n",
       "1   2  manhattan  0.928571\n",
       "2   3  euclidean  0.942857\n",
       "3   3  manhattan  0.938095\n",
       "4   4  euclidean  0.938095\n",
       "5   4  manhattan  0.933333\n",
       "6   5  euclidean  0.942857\n",
       "7   5  manhattan  0.933333\n",
       "8   6  euclidean  0.938095\n",
       "9   6  manhattan  0.928571\n",
       "10  7  euclidean  0.942857\n",
       "11  7  manhattan  0.933333\n",
       "12  8  euclidean  0.938095\n",
       "13  8  manhattan  0.933333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best result:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k     metric     score\n",
       "2  3  euclidean  0.942857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_means = {}\n",
    "\n",
    "for k, d in [(k,d) for k in range(2,9) for d in ['euclidean','manhattan']]:\n",
    "\n",
    "  scores = []\n",
    "  for i in range(0,25):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors = k, metric= d )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    scores.append(clf.score(X_test,y_test))\n",
    "\n",
    "  scores_means[(k,d)] = np.mean(scores)\n",
    "\n",
    "scores_means = pd.DataFrame(scores_means.values(), index=scores_means.keys()).reset_index()\n",
    "scores_means.columns = ['k','metric','score']\n",
    "\n",
    "display(scores_means)\n",
    "print('\\nBest result:\\n')\n",
    "display(scores_means.nlargest(1,'score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desse modo, concluímos que para o nosso conjunto de dados os melhores resultados com o modelo knn são obtidos com os parâmetros k=3 e a métrica Euclidiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>criterion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.940190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.921714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.919048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.925905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.920952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth criterion     score\n",
       "0          2      gini  0.933333\n",
       "1          2   entropy  0.923810\n",
       "2          3      gini  0.940190\n",
       "3          3   entropy  0.923810\n",
       "4          4      gini  0.921714\n",
       "5          4   entropy  0.919048\n",
       "6          5      gini  0.925905\n",
       "7          5   entropy  0.920952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best result:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>criterion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.94019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth criterion    score\n",
       "2          3      gini  0.94019"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# para arvore de decisão\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "scores_means = {}\n",
    "\n",
    "for max_depth, criterion in [(max_depth, criterion) for max_depth in range(2,6) for criterion in ['gini','entropy']]:\n",
    "\n",
    "  scores = []\n",
    "  for i in range(0,25):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    scores.append(clf.score(X_test,y_test))\n",
    "\n",
    "  scores_means[(max_depth, criterion)] = np.mean(scores)\n",
    "\n",
    "scores_means = pd.DataFrame(scores_means.values(), index=scores_means.keys()).reset_index()\n",
    "scores_means.columns = ['max_depth', 'criterion' ,'score']\n",
    "\n",
    "display(scores_means)\n",
    "print('\\nBest result:\\n')\n",
    "display(scores_means.nlargest(1,'score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Aqui o melhor modelo de Árvore de Decisão apresenta um score inferior ao do modelo de K-Vizinhos mais Próximos como k=3 e métrica euclidiana e, assim, optaríamos por este último se levarmos somente o critério de acuracidade como o critério de seleção do melhor modelo, e uma alternativa comum é empregarmos o F1, e o procedimento poderia ser o mesmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pratica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O último refinamento que faremos no procedimento de busca de melhores hiperparâmetros consiste em empregarmos GridSearchCV() do scikit-learn. Essa função automatiza a busca de melhores hiperparâmetros que fizemos acima implementando de forma manual os diferentes estimadores para um espaço de hiperparâmetros em for k, d in [(k,d) for k in range(2,9) for d in ['euclidean','manhattan']]:... e podendo ser aplicada a qualquer estimador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Qualquer parâmetro de um estimador pode ser otimizado desta maneira e para encontrar os nomes e valores dos parâmetros de um determinado estimador você pode empregar o método estimator.get_params()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of KNeighborsClassifier()>\n",
      "<bound method BaseEstimator.get_params of LogisticRegression()>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DecisionTreeClassifier(criterion='entropy', max_depth=3)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier()\n",
    "print(clf.get_params)\n",
    "# e do mesmo modo os hiperparâmetros da regressão logística são também obtidos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "print(LogisticRegression().get_params)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, criterion='entropy')\n",
    "clf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(metric='manhattan')\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.94      0.96      0.95       138\n",
      "   malignant       0.91      0.89      0.90        72\n",
      "\n",
      "    accuracy                           0.93       210\n",
      "   macro avg       0.93      0.92      0.93       210\n",
      "weighted avg       0.93      0.93      0.93       210\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "base_estimator = neighbors.KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': [3,4,5,6,7,8,9,10], 'metric': ['euclidean','manhattan']}\n",
    "\n",
    "clf = GridSearchCV(base_estimator, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Por padrão as funções de pesquisa em grade, como o GridSearchCV() empregam o score padrão do estimador como função de pontuação (no caso de classificação é o accuracy), mas deixamos explícito o parâmetro pois você poderia querer empregar uma função de pontuação dos estimadores baseada em outra métrica.\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# print(clf.cv_results_)\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00652928, 0.00570097, 0.00681386, 0.00757079, 0.00458994,\n",
      "       0.00600152, 0.0065135 , 0.00782247, 0.00463891, 0.00564442,\n",
      "       0.02208323, 0.00770912, 0.00472965, 0.00576663, 0.00668273,\n",
      "       0.00782661, 0.00458245, 0.00566788, 0.00647326, 0.00737758,\n",
      "       0.00458941, 0.00573297, 0.00656924, 0.00761051, 0.00465937,\n",
      "       0.00581107, 0.00669041, 0.00768285, 0.00470223, 0.00570092,\n",
      "       0.00676513, 0.00773587]), 'std_fit_time': array([1.26768844e-03, 3.75386569e-04, 3.86738529e-04, 2.35699667e-04,\n",
      "       6.00937044e-05, 6.92466418e-04, 3.84156185e-05, 4.38801902e-04,\n",
      "       3.19320724e-05, 9.10415135e-05, 3.05477411e-02, 9.54454341e-05,\n",
      "       6.68133091e-05, 1.10020810e-04, 1.67766736e-05, 1.20808499e-04,\n",
      "       7.20963591e-05, 2.00688088e-04, 8.05780588e-05, 6.71696524e-05,\n",
      "       8.51632499e-05, 9.61218321e-05, 4.03158979e-05, 1.21878626e-04,\n",
      "       6.30807803e-05, 1.99629549e-04, 5.82230862e-05, 3.05262941e-05,\n",
      "       1.14618065e-04, 3.59803891e-05, 1.45170487e-04, 7.75681721e-05]), 'mean_score_time': array([0.00161972, 0.00114713, 0.00122261, 0.00120544, 0.00110569,\n",
      "       0.00131521, 0.00116863, 0.00122738, 0.00112309, 0.00116692,\n",
      "       0.00128589, 0.00122471, 0.00111613, 0.001194  , 0.00119348,\n",
      "       0.00123405, 0.00112944, 0.00119848, 0.00118999, 0.00120039,\n",
      "       0.00111222, 0.00124002, 0.00118337, 0.00123901, 0.00112987,\n",
      "       0.00119777, 0.00121694, 0.00122294, 0.00112476, 0.00116   ,\n",
      "       0.00119324, 0.00123672]), 'std_score_time': array([2.77973554e-04, 1.74808788e-05, 4.61151087e-05, 2.78143655e-05,\n",
      "       2.13719882e-05, 2.72275587e-04, 2.07150487e-05, 3.11823794e-05,\n",
      "       1.90302836e-05, 1.94229068e-05, 5.43156247e-05, 1.90301642e-05,\n",
      "       8.81259057e-06, 5.17259534e-05, 2.22848814e-05, 3.45961707e-05,\n",
      "       3.64988866e-05, 8.21278331e-05, 3.39732337e-05, 1.40447769e-05,\n",
      "       1.63611439e-05, 3.87756870e-05, 1.64992547e-05, 5.86008230e-05,\n",
      "       3.05492267e-05, 5.95404088e-05, 4.32928752e-05, 2.60366188e-05,\n",
      "       2.65022815e-05, 1.59655734e-05, 1.53948263e-05, 2.95844314e-05]), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=np.str_('?'),\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 2, 2,\n",
      "                   2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=999999), 'param_n_estimators': masked_array(data=[3, 4, 5, 6, 3, 4, 5, 6, 3, 4, 5, 6, 3, 4, 5, 6, 3, 4,\n",
      "                   5, 6, 3, 4, 5, 6, 3, 4, 5, 6, 3, 4, 5, 6],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=999999), 'params': [{'criterion': 'gini', 'max_depth': 2, 'n_estimators': 3}, {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 4}, {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 5}, {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 6}, {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 3}, {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 4}, {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 5}, {'criterion': 'gini', 'max_depth': 3, 'n_estimators': 6}, {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 3}, {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 4}, {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 5}, {'criterion': 'gini', 'max_depth': 4, 'n_estimators': 6}, {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 3}, {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 4}, {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 5}, {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 6}, {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 3}, {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 4}, {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 5}, {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 6}, {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 3}, {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 4}, {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 5}, {'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 6}, {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 3}, {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 4}, {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 5}, {'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 6}, {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 3}, {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 4}, {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 5}, {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 6}], 'split0_test_score': array([0.94897959, 0.92857143, 0.94897959, 0.92857143, 0.89795918,\n",
      "       0.91836735, 0.91836735, 0.91836735, 0.89795918, 0.94897959,\n",
      "       0.92857143, 0.93877551, 0.93877551, 0.95918367, 0.93877551,\n",
      "       0.94897959, 0.98979592, 0.98979592, 0.97959184, 0.96938776,\n",
      "       0.97959184, 0.95918367, 0.97959184, 0.95918367, 0.92857143,\n",
      "       0.94897959, 0.96938776, 0.95918367, 0.95918367, 0.95918367,\n",
      "       0.97959184, 0.95918367]), 'split1_test_score': array([0.96938776, 0.96938776, 0.93877551, 0.94897959, 0.94897959,\n",
      "       0.95918367, 0.96938776, 0.95918367, 0.97959184, 0.97959184,\n",
      "       0.96938776, 0.96938776, 0.96938776, 0.97959184, 0.96938776,\n",
      "       0.95918367, 0.94897959, 0.94897959, 0.92857143, 0.92857143,\n",
      "       0.93877551, 0.94897959, 0.95918367, 0.94897959, 0.96938776,\n",
      "       0.97959184, 0.97959184, 0.96938776, 0.97959184, 0.97959184,\n",
      "       0.96938776, 0.96938776]), 'split2_test_score': array([0.94897959, 0.93877551, 0.94897959, 0.94897959, 0.93877551,\n",
      "       0.94897959, 0.95918367, 0.95918367, 0.96938776, 0.94897959,\n",
      "       0.95918367, 0.95918367, 0.97959184, 0.93877551, 0.95918367,\n",
      "       0.95918367, 0.94897959, 0.95918367, 0.95918367, 0.95918367,\n",
      "       0.94897959, 0.94897959, 0.96938776, 0.96938776, 0.95918367,\n",
      "       0.95918367, 0.95918367, 0.95918367, 0.96938776, 0.95918367,\n",
      "       0.96938776, 0.96938776]), 'split3_test_score': array([0.94897959, 0.94897959, 0.92857143, 0.93877551, 0.94897959,\n",
      "       0.94897959, 0.94897959, 0.96938776, 0.94897959, 0.94897959,\n",
      "       0.95918367, 0.95918367, 0.93877551, 0.93877551, 0.94897959,\n",
      "       0.93877551, 0.95918367, 0.91836735, 0.91836735, 0.94897959,\n",
      "       0.94897959, 0.94897959, 0.95918367, 0.95918367, 0.95918367,\n",
      "       0.95918367, 0.95918367, 0.95918367, 0.95918367, 0.95918367,\n",
      "       0.95918367, 0.95918367]), 'split4_test_score': array([0.98969072, 0.98969072, 0.98969072, 0.98969072, 0.97938144,\n",
      "       0.97938144, 0.96907216, 0.95876289, 0.96907216, 0.96907216,\n",
      "       0.98969072, 0.98969072, 0.96907216, 0.96907216, 0.97938144,\n",
      "       0.97938144, 0.98969072, 0.98969072, 0.98969072, 0.98969072,\n",
      "       0.97938144, 0.98969072, 0.98969072, 0.98969072, 0.98969072,\n",
      "       0.97938144, 0.98969072, 0.97938144, 0.98969072, 0.98969072,\n",
      "       1.        , 0.98969072]), 'mean_test_score': array([0.96120345, 0.955081  , 0.95099937, 0.95099937, 0.94281506,\n",
      "       0.95097833, 0.95299811, 0.95297707, 0.95299811, 0.95912056,\n",
      "       0.96120345, 0.96324427, 0.95912056, 0.95707974, 0.95914159,\n",
      "       0.95710078, 0.9673259 , 0.96120345, 0.955081  , 0.95916263,\n",
      "       0.95914159, 0.95916263, 0.97140753, 0.96528508, 0.96120345,\n",
      "       0.96526404, 0.97140753, 0.96526404, 0.97140753, 0.96936672,\n",
      "       0.9755102 , 0.96936672]), 'std_test_score': array([0.01628972, 0.02194707, 0.02077313, 0.02077313, 0.02623536,\n",
      "       0.01972577, 0.01887165, 0.01776324, 0.02925629, 0.01285788,\n",
      "       0.01975609, 0.01654602, 0.0170374 , 0.01627961, 0.01437137,\n",
      "       0.01346755, 0.01867917, 0.02689791, 0.02780682, 0.02037662,\n",
      "       0.01702453, 0.01576736, 0.01186746, 0.01380428, 0.01975609,\n",
      "       0.012196  , 0.01186746, 0.00808973, 0.01186746, 0.01287402,\n",
      "       0.01384149, 0.01113961]), 'rank_test_score': array([12, 24, 29, 29, 32, 31, 26, 28, 27, 20, 12, 11, 21, 23, 18, 22,  7,\n",
      "       12, 25, 16, 18, 16,  2,  8, 12,  9,  2,  9,  2,  5,  1,  6],\n",
      "      dtype=int32)}\n",
      "RandomForestClassifier(criterion='entropy', max_depth=5, n_estimators=5,\n",
      "                       random_state=123)\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.98      0.94      0.96       138\n",
      "   malignant       0.90      0.97      0.93        72\n",
      "\n",
      "    accuracy                           0.95       210\n",
      "   macro avg       0.94      0.96      0.95       210\n",
      "weighted avg       0.95      0.95      0.95       210\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anahelena/.local/lib/python3.12/site-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "base_estimator = RandomForestClassifier(random_state=123)\n",
    "param_grid = {'n_estimators':[3,4,5,6],'criterion':['gini','entropy'],'max_depth':[2,3,4,5]}\n",
    "\n",
    "clf = GridSearchCV(base_estimator, param_grid, cv=5, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.cv_results_)\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "print()\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Selecionar um estimador (um classificador ou um regressor)\n",
    "* Definir um espaço de hiperparâmetros que desejamos avaliar\n",
    "* Definir uma função de pontuação (score function)\n",
    "* Empregar um esquema de validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc_scores = cross_val_score(clf, X_train, y_train, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![imagem](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97959184 0.93877551 1.         0.97959184 0.95918367 0.95918367\n",
      " 1.         0.93877551 0.97959184 0.95833333] \n",
      "\n",
      "accuracy: 0.969 +/- 0.042 \n",
      "\n",
      "accuracy: 0.971 +/- 0.008\n",
      "f1_macro: 0.968 +/- 0.009\n",
      "precision_macro: 0.970 +/- 0.009\n",
      "recall_macro: 0.967 +/- 0.018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 3, metric= 'euclidean' )\n",
    "\n",
    "acc_scores = cross_val_score(clf, X_train, y_train, cv = 10)\n",
    "\n",
    "print(acc_scores, '\\n')\n",
    "print(\"accuracy: %0.3f +/- %0.3f\" % (acc_scores.mean(), acc_scores.std() * 2),'\\n')\n",
    "\n",
    "for metric in ['accuracy','f1_macro','precision_macro','recall_macro']:\n",
    "  scores = cross_val_score(clf, X_train, y_train, cv = 4, scoring=metric)\n",
    "  print(metric + \": %0.3f +/- %0.3f\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "4       3450.0  Female  \n",
       "5       3650.0    Male  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = sns.load_dataset('penguins')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Treinamento e teste\n",
    "# As features (X) e o alvo (y)\n",
    "X = df[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
    "y = df['species']\n",
    "\n",
    "# Dividindo em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "# Criando o dicionário de modelos que iremos testar\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O obtenha a acuracidade média dos modelos para um cv de 5 partições. Explore a saída do estimador cross_val_score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest, score = 0.9760\n",
      "DecisionTree, score = 0.9580\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5)\n",
    "    print(f\"{name}, score = {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97014925, 0.98507463, 0.91044776, 0.98484848, 0.93939394])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Acima foram empregadas partições diferentes para cada modelo. Empregue os estimadores KFold (ou alternativamente o StratifiedKFold), para fixar as partições e obtenha o novo score dos modelos fazendo a seleção agora pela métrica f1_macro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest, score = 0.9756\n",
      "DecisionTree, score = 0.9666\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring='f1_macro')\n",
    "    print(f\"{name}, score = {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{RandomForestClassifier(): np.float64(0.9721484905798631),\n",
       " DecisionTreeClassifier(): np.float64(0.960080404872922),\n",
       " LogisticRegression(max_iter=1000): np.float64(0.9823596229934367),\n",
       " KNeighborsClassifier(): np.float64(0.6890947070491956)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empregue o código anterior para selecionar programaticamente o melhor modelo, treinar, aplicar ao conjunto de teste e obter a acuracidade nesse conjunto.\n",
    "\n",
    "models_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    models_scores[model] = cross_val_score(model, X, y, cv=kf, scoring='f1_macro').mean()\n",
    "\n",
    "models_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "best_model = max(models_scores, key=models_scores.get)\n",
    "print(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "y_pred = model.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'deprecated',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Empregando o `GridSearchCV`. O `GridSearchCV` permite automatizar todas essas operações.\n",
    "\n",
    "Empregue o exemplo de código abaixo para corrigir, como fizemos antes, o uso de partições diferentes na avaliação dos modelos (use o `KFold`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo: LogisticRegression(max_iter=1000)\n",
      "Acurácia no teste: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anahelena/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Criando o pipeline com pré-processamento e modelo\n",
    "pipeline = Pipeline([('model', None)])\n",
    "# pipeline = Pipeline([('scaler', StandardScaler()), ('model', None)])\n",
    "\n",
    "# Definindo o dicionário de parâmetros para o GridSearchCV (somente diferentes modelos)\n",
    "param_grid = [\n",
    "    {'model': [models['RandomForest']]},\n",
    "    {'model': [models['DecisionTree']], 'model__max_depth': [5,6,7]},\n",
    "    {'model': [models['LogisticRegression']]},\n",
    "    {'model': [models['KNN']], 'model__n_neighbors': [3, 5, 7, 9]}\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# Usando o GridSearchCV para encontrar o melhor modelo\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=kf, scoring='accuracy')\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, cv=kf, scoring='f1_macro')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibindo o melhor modelo encontrado\n",
    "print(f\"Melhor modelo: {grid_search.best_estimator_['model']}\")\n",
    "\n",
    "# Avaliando o desempenho no conjunto de teste\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia no teste: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### + hiperparametros braçal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best result:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>0.975489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k     metric     score\n",
       "7  5  manhattan  0.975489"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/MASS/biopsy.csv',index_col=0)\n",
    "df['V6'] = df[['V6']].fillna(df['V6'].mean())\n",
    "\n",
    "X = df.drop(columns=['ID','class'])\n",
    "y = df['class']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "scores_means = {}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)\n",
    "\n",
    "for k, d in [(k,d) for k in range(2,9) for d in ['euclidean','manhattan']]:\n",
    "\n",
    "  clf = neighbors.KNeighborsClassifier(n_neighbors = k, metric= d )\n",
    "\n",
    "  acc_scores = cross_val_score(clf, X_train, y_train, cv = 5)\n",
    "\n",
    "  scores_means[(k,d)] = acc_scores.mean()\n",
    "\n",
    "scores_means = pd.DataFrame(scores_means.values(), index=scores_means.keys()).reset_index()\n",
    "scores_means.columns = ['k','metric','score']\n",
    "\n",
    "# display(scores_means)\n",
    "print('\\nBest result:\\n')\n",
    "display(scores_means.nlargest(1,'score'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(metric='manhattan', n_neighbors=np.int64(5))\n",
      "accuracy: 0.933 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicando o melhor modelo\n",
    "\n",
    "k = scores_means.nlargest(1,'score').k.values[0]\n",
    "metric = scores_means.nlargest(1,'score').metric.values[0]\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = k, metric= metric )\n",
    "print(clf)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"accuracy: %0.3f\" % clf.score(X_test,y_test),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
